/* AUTOGENERATED DO NOT MODIFY */

/**
  ******************************************************************************
  * @file    network.c
  * @brief   NN Code autogenerated DO NOT MODIFY IT
  ******************************************************************************
  * @attention
  *
  * Copyright (c) 2023 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  ******************************************************************************
  */

/*
 * GIT_SHA         "0307e413493a9893cb1f0a1266b856e2af3bba2b"
 * GIT_BRANCH      "STAI-2.0"
 * GIT_DESCRIPTION "STAI-2.0-RC1-1-1-g0307e413"
 *
 * Command Line options:
 * --onnx-input = "C:/Users/noaht/.stm32cubemx/network_output/snn_model_OE_3_1_0.onnx"
 * --out-dir-prefix = "C:/Users/noaht/AppData/Local/Temp/mxAI_workspace513480714218100722356781876297198/neural_art__network/"
 * --all-buffers-info = true
 * --mvei = true
 * --load-mdesc-file = "C:/Users/noaht/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.0.0/Utilities/configs/stm32n6"
 * --load-mpool-file = "C:/Users/noaht/STM32Cube/Repository/Packs/STMicroelectronics/X-CUBE-AI/10.0.0/scripts/N6_scripts/my_mpools/stm32n6"
 * --cache-maintenance = true
 * --enable-virtual-mem-pools = true
 * --native-float = true
 * --json-quant-file = "C:/Users/noaht/.stm32cubemx/network_output/snn_model_OE_3_1_0_Q.json"
 * --optimization = 3
 * --Os = true
 * --Omax-ca-pipe = 4
 * --Ocache-opt = true
 * --output-info-file = "c_info"
 * --Oalt-sched = true
 * --no-hw-sw-parallelism = true
 * --Oshuffle-dma = true
 */

#include "ll_aton_NN_interface.h"
#include "ll_aton.h"
#include "ll_aton_lib.h"
#include "ll_aton_version.h"
#include "ll_sw.h"

#if LL_ATON_VERSION_MAJOR != 1 || LL_ATON_VERSION_MINOR != 0 || LL_ATON_VERSION_MICRO != 0 || LL_ATON_VERSION_DEV != 16
#  warning "Possible mismatch in ll_aton library used"
#endif

#if !defined(LL_ATON_DBG_BUFFER_INFO_EXCLUDED)
#  define LL_ATON_DBG_BUFFER_INFO_EXCLUDED 0
#endif

/* global pool 7 is ? */
/* index=7 file postfix=xSPI1 name=hyperRAM offset=0x90000000  absolute_mode size=33554424 READ_WRITE THROUGHPUT=MID LATENCY=HIGH byte width=2 freq ratio=5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=380 write_power=340 use4initializers=YES score=82  */
/* global pool 8 is 11.00 KB */
/* index=8 file postfix=xSPI2 name=octoFlash offset=0x70000000  absolute_mode size=67108856 READ_ONLY THROUGHPUT=MID LATENCY=HIGH byte width=1 freq ratio=6 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=110 write_power=400 use4initializers=YES score=50  */
/* global pool 1 is 512 B */
/* index=1 file postfix=AXISRAM5 name=npuRAM5 offset=0x342e0000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 2 is ? */
/* index=2 file postfix=AXISRAM4 name=npuRAM4 offset=0x34270000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 3 is ? */
/* index=3 file postfix=AXISRAM3 name=npuRAM3 offset=0x34200000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 0 is ? */
/* index=0 file postfix=AXISRAM6 name=npuRAM6 offset=0x34350000  absolute_mode size=458744 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=15.79 use4initializers=NO score=94  */
/* global pool 10 is 1.88 MB */
/* index=10 file postfix=AXISRAM2_AXISRAM3_AXISRAM4_AXISRAM5_AXISRAM6 name=cpuRAM2_npuRAM3_npuRAM4_npuRAM5_npuRAM6 offset=0x34100000  absolute_mode size=2883576 vpool READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=16.201 use4initializers=NO score=85  */
/* global pool 4 is ? */
/* index=4 file postfix=AXISRAM2 name=cpuRAM2 offset=0x34100000  absolute_mode size=1048576 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=17.324 write_power=15.321 use4initializers=NO score=84  */
/* global pool 5 is ? */
/* index=5 file postfix=AXISRAM1 name=cpuRAM1 offset=0x34064000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=16.616 write_power=14.522 use4initializers=NO score=84  */
/* global pool 6 is ? */
/* index=6 file postfix=AXIFLEXMEM name=flexMEM offset=0x34000000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=9.381 write_power=8.569 use4initializers=NO score=84  */

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Input_Buffer_Default(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Input_Buffer_Default(uint32_t num)
{
  { 
    return NULL;
  }
}

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Output_Buffer_Default(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Output_Buffer_Default(uint32_t num)
{
  { 
    return NULL;
  }
}

bool LL_ATON_EC_Network_Init_Default(void)
{
  return true;
}

bool LL_ATON_EC_Inference_Init_Default(void)
{
  return true;
}

/* scheduling epoch=0    nodes=7   ------------------------------------------------------------------- */

/* scheduling epoch=1    nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=2    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_2(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Gemm_1_conv_4 */
  Conv_sw_info conv1_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 10,
    .general.input.dim.num_elem = 10,
    .general.input.stride.b = 40,
    .general.input.stride.h = 40,
    .general.input.stride.w = 40,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 64,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 10,
    .weights.dim.num_elem = 640,
    .weights.stride.b = 40,
    .weights.stride.h = 40,
    .weights.stride.w = 40,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 8192) /* Equivalent hex address = 0x70002000UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 64,
    .general.output.stride.b = 256,
    .general.output.stride.h = 256,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_1_conv_4 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv1_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=3    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_3(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Gemm_1_conv_4_addbias18 */
  Arith_sw_info arith2_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 64,
    .general.input.stride.b = 256,
    .general.input.stride.h = 256,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 64,
    .operand.dim.num_elem = 64,
    .operand.stride.b = 256,
    .operand.stride.h = 256,
    .operand.stride.w = 256,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 10752) /* Equivalent hex address = 0x70002a00UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 64,
    .general.output.stride.b = 256,
    .general.output.stride.h = 256,
    .general.output.stride.w = 256,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_1_conv_4_addbias18 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith2_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=4    nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=5    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_5(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Relu node=Relu_2 */
  Activ_sw_info activ3_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 64,
    .general.input.stride.b = 256,
    .general.input.stride.h = 256,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 64,
    .general.output.dim.num_elem = 64,
    .general.output.stride.b = 256,
    .general.output.stride.h = 256,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_RELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Relu_2 mapped on EmbedNets (FLOAT) as Relu | Category: Computational */
  ll_sw_forward_activ(&activ3_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=6    nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=7    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_7(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Gemm_3_conv_10 */
  Conv_sw_info conv4_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 64,
    .general.input.dim.num_elem = 64,
    .general.input.stride.b = 256,
    .general.input.stride.h = 256,
    .general.input.stride.w = 256,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 32,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 64,
    .weights.dim.num_elem = 2048,
    .weights.stride.b = 256,
    .weights.stride.h = 256,
    .weights.stride.w = 256,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 0) /* Equivalent hex address = 0x70000000UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 32,
    .general.output.stride.b = 128,
    .general.output.stride.h = 128,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_3_conv_10 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv4_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 384) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 384) /* Equivalent hex address = 0x342e0180UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=8    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_8(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Gemm_3_conv_10_addbias20 */
  Arith_sw_info arith5_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 32,
    .general.input.stride.b = 128,
    .general.input.stride.h = 128,
    .general.input.stride.w = 128,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 32,
    .operand.dim.num_elem = 32,
    .operand.stride.b = 128,
    .operand.stride.h = 128,
    .operand.stride.w = 128,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 11136) /* Equivalent hex address = 0x70002b80UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 32,
    .general.output.stride.b = 128,
    .general.output.stride.h = 128,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_3_conv_10_addbias20 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith5_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=9    nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=10   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_10(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Relu node=Relu_4 */
  Activ_sw_info activ6_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 32,
    .general.input.stride.b = 128,
    .general.input.stride.h = 128,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 32,
    .general.output.stride.b = 128,
    .general.output.stride.h = 128,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_RELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Relu_4 mapped on EmbedNets (FLOAT) as Relu | Category: Computational */
  ll_sw_forward_activ(&activ6_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=11   nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=12   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_12(const void *epoch_block)
{
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation for unaligned buffer start or end address (only line) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 160) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 160) /* Equivalent hex address = 0x342e00a0UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Gemm_5_conv_16 */
  Conv_sw_info conv7_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 32,
    .general.input.stride.b = 128,
    .general.input.stride.h = 128,
    .general.input.stride.w = 128,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 1,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 32,
    .weights.dim.num_elem = 32,
    .weights.stride.b = 128,
    .weights.stride.h = 128,
    .weights.stride.w = 128,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 11008) /* Equivalent hex address = 0x70002b00UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 1,
    .general.output.dim.num_elem = 1,
    .general.output.stride.b = 4,
    .general.output.stride.h = 4,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_5_conv_16 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv7_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 160) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 160) /* Equivalent hex address = 0x342e00a0UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=13   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_13(const void *epoch_block)
{
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation for unaligned buffer start or end address (only line) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Gemm_5_conv_16_addbias22 */
  Arith_sw_info arith8_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 1,
    .general.input.dim.num_elem = 1,
    .general.input.stride.b = 4,
    .general.input.stride.h = 4,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 128) /* Equivalent hex address = 0x342e0080UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 1,
    .operand.dim.num_elem = 1,
    .operand.stride.b = 4,
    .operand.stride.h = 4,
    .operand.stride.w = 4,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70000000UL + 11264) /* Equivalent hex address = 0x70002c00UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 1,
    .general.output.dim.num_elem = 1,
    .general.output.stride.b = 4,
    .general.output.stride.h = 4,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_5_conv_16_addbias22 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith8_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=14   nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=15   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_15(const void *epoch_block)
{
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation for unaligned buffer start or end address (only line) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Sigmoid node=Sigmoid_6 */
  Activ_sw_info activ9_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 1,
    .general.input.dim.num_elem = 1,
    .general.input.stride.b = 4,
    .general.input.stride.h = 4,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 1,
    .general.output.dim.num_elem = 1,
    .general.output.stride.b = 4,
    .general.output.stride.h = 4,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_SIGMOID,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Sigmoid_6 mapped on EmbedNets (FLOAT) as Sigmoid | Category: Computational */
  ll_sw_forward_activ(&activ9_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=16   nodes=1   ------------------------------------------------------------------- */

/* scheduling DONE                 ------------------------------------------------------------------- */

const EpochBlock_ItemTypeDef *LL_ATON_EpochBlockItems_Default(void) {

  static const EpochBlock_ItemTypeDef ll_atonn_rt_epoch_block_array[] = {
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_2,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 2,
      .last_epoch_num = 2,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_3,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 3,
      .last_epoch_num = 3,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_5,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 5,
      .last_epoch_num = 5,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_7,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 7,
      .last_epoch_num = 7,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_8,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 8,
      .last_epoch_num = 8,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_10,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 10,
      .last_epoch_num = 10,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_12,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 12,
      .last_epoch_num = 12,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_13,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 13,
      .last_epoch_num = 13,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_15,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 15,
      .last_epoch_num = 15,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .flags = EpochBlock_Flags_last_eb,
    },
  };


  return ll_atonn_rt_epoch_block_array;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Input_Buffers_Info_Default(void)
{
  static const uint32_t buff_info__shape_1_10[] = { 1, 1, 10, 1 };
  static const uint32_t buff_info__mem_shape_U_1_10[] = { 1, 10 };
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const uint32_t buff_info__shape_64_10_1_1[] = { 64, 1, 1, 10 };
  static const uint32_t buff_info__mem_shape_F_64_10_1_1[] = { 64, 10, 1, 1 };
  static const uint32_t buff_info__shape_32_64_1_1[] = { 32, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_F_32_64_1_1[] = { 32, 64, 1, 1 };
  static const uint32_t buff_info__shape_1_32_1_1[] = { 1, 1, 1, 32 };
  static const uint32_t buff_info__mem_shape_F_1_32_1_1[] = { 1, 32, 1, 1 };
  static const uint32_t buff_info__shape_64_1_1[] = { 1, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_F_64_1_1[] = { 64, 1, 1 };
  static const uint32_t buff_info__shape_32_1_1[] = { 1, 1, 1, 32 };
  static const uint32_t buff_info__mem_shape_F_32_1_1[] = { 32, 1, 1 };
  static const uint32_t buff_info__shape_1_1_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_1_1_1[] = { 1, 1, 1 };
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Input_0_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 40,
      .offset_limit = 104,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_10,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_10,
    },
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = "Gemm_1_weights_transposed_3",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 8192,
      .offset_end = 10752,
      .offset_limit = 10816,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 10,
      .mem_shape = buff_info__mem_shape_F_64_10_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_64_10_1_1,
    },
    {
      .name = "Gemm_3_weights_transposed_9",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_F_32_64_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_32_64_1_1,
    },
    {
      .name = "Gemm_5_weights_transposed_15",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 11008,
      .offset_end = 11136,
      .offset_limit = 11200,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_1_32_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_1_1,
    },
    {
      .name = "Gemm_1_bias_copy19",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 10752,
      .offset_end = 11008,
      .offset_limit = 11072,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_F_64_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_64_1_1,
    },
    {
      .name = "Gemm_3_bias_copy21",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 11136,
      .offset_end = 11264,
      .offset_limit = 11328,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_32_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_32_1_1,
    },
    {
      .name = "Gemm_5_bias_copy23",
      .addr_base = {(unsigned char *)(0x70000000UL) /* Equivalent hex address = 0x70000000UL */},
      .offset_start = 11264,
      .offset_end = 11268,
      .offset_limit = 11336,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1_1,
    },
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Output_Buffers_Info_Default(void)
{
  static const uint32_t buff_info__shape_1_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_U_1_1[] = { 1, 1 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Sigmoid_6_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 4,
      .offset_limit = 72,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 15,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_1,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Internal_Buffers_Info_Default(void)
{
  static const uint32_t buff_info__shape_1_10_1_1[] = { 1, 1, 1, 10 };
  static const uint32_t buff_info__mem_shape_F_1_10_1_1[] = { 1, 10, 1, 1 };
  static const uint32_t buff_info__shape_1_64_1_1[] = { 1, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_F_1_64_1_1[] = { 1, 64, 1, 1 };
  static const uint32_t buff_info__shape_1_64[] = { 1, 1, 64, 1 };
  static const uint32_t buff_info__mem_shape_U_1_64[] = { 1, 64 };
  static const uint32_t buff_info__shape_1_32_1_1[] = { 1, 1, 1, 32 };
  static const uint32_t buff_info__mem_shape_F_1_32_1_1[] = { 1, 32, 1, 1 };
  static const uint32_t buff_info__shape_1_32[] = { 1, 1, 32, 1 };
  static const uint32_t buff_info__mem_shape_U_1_32[] = { 1, 32 };
  static const uint32_t buff_info__shape_1_1_1_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_1_1_1_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__shape_1_1[] = { 1, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_U_1_1[] = { 1, 1 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Gemm_1_reshape_x_2",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 40,
      .offset_limit = 104,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 1,
      .batch = 10,
      .mem_shape = buff_info__mem_shape_F_1_10_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_10_1_1,
    },
    {
      .name = "Gemm_1_conv_4_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 256,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 2,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_F_1_64_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_1_1,
    },
    {
      .name = "Gemm_1_conv_4",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 256,
      .offset_limit = 320,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 3,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_F_1_64_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_1_1,
    },
    {
      .name = "Gemm_1_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 256,
      .offset_limit = 320,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 4,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_64,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64,
    },
    {
      .name = "Relu_2_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 256,
      .offset_limit = 320,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 5,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_64,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64,
    },
    {
      .name = "Gemm_3_reshape_x_8",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 256,
      .offset_limit = 320,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 6,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_F_1_64_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_64_1_1,
    },
    {
      .name = "Gemm_3_conv_10_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 256,
      .offset_end = 384,
      .offset_limit = 448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 7,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_1_32_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_1_1,
    },
    {
      .name = "Gemm_3_conv_10",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 8,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_1_32_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_1_1,
    },
    {
      .name = "Gemm_3_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 9,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_32,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32,
    },
    {
      .name = "Relu_4_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 10,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_32,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32,
    },
    {
      .name = "Gemm_5_reshape_x_14",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 128,
      .offset_limit = 192,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 11,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_1_32_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_1_1,
    },
    {
      .name = "Gemm_5_conv_16_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 128,
      .offset_end = 132,
      .offset_limit = 200,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 12,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1_1_1,
    },
    {
      .name = "Gemm_5_conv_16",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 4,
      .offset_limit = 72,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 13,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1_1_1,
    },
    {
      .name = "Gemm_5_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 4,
      .offset_limit = 72,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 14,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_1,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

